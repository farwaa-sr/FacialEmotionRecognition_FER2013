{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disk\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Emotion Report:\n",
      "Fearful: 20.00%\n",
      "Surprised: 10.00%\n",
      "Neutral: 50.00%\n",
      "Angry: 10.00%\n",
      "Happy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import Tk, Label, Button\n",
    "from PIL import Image, ImageTk\n",
    "from keras.models import model_from_json\n",
    "\n",
    "window = Tk()\n",
    "window.title(\"Emotion Detection\")\n",
    "\n",
    "#emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "# Load JSON and create model\n",
    "# Load JSON and create model\n",
    "json_file = open('model/emotion_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "emotion_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into the model\n",
    "emotion_model.load_weights(\"model/emotion_model.h5\")\n",
    "\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "\n",
    "# Start the webcam feed\n",
    "cap = cv2.VideoCapture(0)  # Open the webcam (device index 0)\n",
    "\n",
    "emotion_report = []  # Variable to store emotion predictions\n",
    "\n",
    "while True:\n",
    "    # Read frame from the webcam feed\n",
    "    ret, frame = cap.read()  # Capture a frame from the webcam\n",
    "    frame = cv2.resize(frame, (1280, 720))  # Resize the frame to a desired size\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)  # Flip the frame horizontally\n",
    "\n",
    "    face_detector_front = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')  # Load the face detector model\n",
    "    gray_frame_front = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert the frame to grayscale\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    num_faces = face_detector_front.detectMultiScale(gray_frame_front, scaleFactor=1.3, minNeighbors=5)  # Detect faces using the loaded model\n",
    "\n",
    "    # Process each face detected\n",
    "    for (x, y, w, h) in num_faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (0, 255, 0), 4)  # Draw a rectangle around the face region\n",
    "        roi_gray_frame_front = gray_frame_front[y:y + h, x:x + w]  # Extract the region of interest (face) from the frame\n",
    "        cropped_img_front = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame_front, (48, 48)), -1), 0)  # Preprocess the face image for emotion prediction\n",
    "\n",
    "        # Predict the emotions\n",
    "        emotion_prediction_front = emotion_model.predict(cropped_img_front)  # Predict the emotions using the loaded model\n",
    "        maxindex_front = int(np.argmax(emotion_prediction_front))  # Find the index of the predicted emotion with the highest probability\n",
    "        cv2.putText(frame, emotion_dict[maxindex_front], (x+5, y-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)  # Display the predicted emotion as text on the frame\n",
    "\n",
    "        # Append emotion to the report\n",
    "        emotion_report.append(emotion_dict[maxindex_front])  # Store the predicted emotion in the emotion report list\n",
    "\n",
    "    cv2.imshow('Emotion Detection', frame)  # Display the frame with emotion detection\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Exit the loop if 'q' is pressed\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the webcam\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "# Generate Emotion Report\n",
    "emotion_count = {}  # Dictionary to store the count of each emotion\n",
    "total_emotions = len(emotion_report)  # Total number of emotions in the report\n",
    "\n",
    "for emotion in emotion_report:\n",
    "    if emotion in emotion_count:\n",
    "        emotion_count[emotion] += 1  # Increment the count if the emotion already exists in the dictionary\n",
    "    else:\n",
    "        emotion_count[emotion] = 1  # Initialize the count if the emotion doesn't exist in the dictionary\n",
    "\n",
    "emotion_percentage = {}  # Dictionary to store the percentage of each emotion\n",
    "for emotion, count in emotion_count.items():\n",
    "    percentage = (count / total_emotions) * 100  # Calculate the percentage of each emotion\n",
    "    emotion_percentage[emotion] = percentage  # Store the percentage in the dictionary\n",
    "\n",
    "print(\"Emotion Report:\")\n",
    "for emotion, percentage in emotion_percentage.items():\n",
    "    print(f\"{emotion}: {percentage:.2f}%\")  # Print the emotion report with percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 1s 525ms/step\n",
      "1/1 [==============================] - 0s 481ms/step\n",
      "1/1 [==============================] - 0s 446ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import Tk, Button, Toplevel, Label, messagebox, Frame, filedialog, Entry\n",
    "from PIL import Image, ImageTk\n",
    "from keras.models import model_from_json\n",
    "from tkinter import ttk\n",
    "\n",
    "# Load JSON and create model\n",
    "json_file = open('model/emotion_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "emotion_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into the model\n",
    "emotion_model.load_weights(\"model/emotion_model.h5\")\n",
    "\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "emotion_report = []  # Variable to store emotion predictions\n",
    "\n",
    "def end_detection():\n",
    "    window2.destroy()\n",
    "    window.deiconify()\n",
    "\n",
    "def start_detection():\n",
    "    global cap, window2, label_img, stop_camera, emotion_report\n",
    "\n",
    "    window.withdraw()  # Hide the first window\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    stop_camera = False\n",
    "    emotion_report = []  # Reset emotion report\n",
    "\n",
    "    window2 = Toplevel()\n",
    "    window2.title(\"Emotion Detection\")\n",
    "\n",
    "    background_image = Image.open(\"background_image.jpg\")\n",
    "    background_image = background_image.resize((1400, 1000), Image.LANCZOS)\n",
    "    background_photo = ImageTk.PhotoImage(background_image)\n",
    "\n",
    "    label_background = Label(window2, image=background_photo)\n",
    "    label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "    label_background.image = background_photo\n",
    "\n",
    "    button_frame = Frame(window2, bg='white', padx=20, pady=20)\n",
    "    button_frame.pack(side='bottom')\n",
    "\n",
    "    def stop_detection():\n",
    "        global stop_camera\n",
    "        stop_camera = True\n",
    "        window2.destroy()\n",
    "        window.deiconify()\n",
    "\n",
    "    def generate_report():\n",
    "        global stop_camera, emotion_report\n",
    "        stop_camera = True\n",
    "\n",
    "        if not emotion_report:\n",
    "            messagebox.showerror(\"Error\", \"No emotions detected. Please try again.\")\n",
    "            return\n",
    "\n",
    "        emotion_count = {}\n",
    "        total_emotions = len(emotion_report)\n",
    "\n",
    "        for emotion in emotion_report:\n",
    "            if emotion in emotion_count:\n",
    "                emotion_count[emotion] += 1\n",
    "            else:\n",
    "                emotion_count[emotion] = 1\n",
    "\n",
    "        emotion_percentage = {}\n",
    "        for emotion, count in emotion_count.items():\n",
    "            percentage = (count / total_emotions) * 100\n",
    "            emotion_percentage[emotion] = percentage\n",
    "\n",
    "        overall_mood = max(emotion_percentage, key=emotion_percentage.get)\n",
    "\n",
    "        report_window = Toplevel()\n",
    "        report_window.title(\"Emotion Report\")\n",
    "\n",
    "        # Set the background image for the report window\n",
    "        background_image = Image.open(\"background_image.jpg\")\n",
    "        background_image = background_image.resize((1500, 1000), Image.LANCZOS)\n",
    "        background_photo = ImageTk.PhotoImage(background_image)\n",
    "        label_background = Label(report_window, image=background_photo)\n",
    "        label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "        label_background.image = background_photo  # Attach the image object to the label to prevent it from being garbage collected\n",
    "\n",
    "        report_frame = Frame(report_window)\n",
    "        report_frame.pack()\n",
    "\n",
    "        for emotion, percentage in emotion_percentage.items():\n",
    "            label = Label(report_frame, text=f\"{emotion_dict[emotion]}: {percentage:.2f}%\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label.pack(anchor='center')\n",
    "\n",
    "        label_overall_mood = Label(report_frame, text=f\"Overall Mood: {emotion_dict[overall_mood]}\", font=(\"Arial\", 20, \"bold\"))\n",
    "        label_overall_mood.pack(anchor='center')\n",
    "\n",
    "        def send_report_to_therapist():\n",
    "            report_window.destroy()\n",
    "            details_window = Toplevel()\n",
    "            details_window.title(\"Patient Details\")\n",
    "\n",
    "            # Set the background image for the details window\n",
    "            background_image = Image.open(\"background_image.jpg\")\n",
    "            background_image = background_image.resize((1500, 1000), Image.LANCZOS)\n",
    "            background_photo = ImageTk.PhotoImage(background_image)\n",
    "            label_background = Label(details_window, image=background_photo)\n",
    "            label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "            label_background.image = background_photo\n",
    "\n",
    "            details_frame = Frame(details_window)\n",
    "            details_frame.pack()\n",
    "\n",
    "            # Add labels and entry fields for patient details\n",
    "            label_name = Label(details_frame, text=\"Name:\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label_name.pack()\n",
    "            entry_name = Entry(details_frame, font=(\"Arial\", 14))\n",
    "            entry_name.pack()\n",
    "\n",
    "            label_contact = Label(details_frame, text=\"Contact No:\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label_contact.pack()\n",
    "            entry_contact = Entry(details_frame, font=(\"Arial\", 14))\n",
    "            entry_contact.pack()\n",
    "\n",
    "            label_medical = Label(details_frame, text=\"Medical Issues:\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label_medical.pack()\n",
    "            entry_medical = Entry(details_frame, font=(\"Arial\", 14))\n",
    "            entry_medical.pack()\n",
    "\n",
    "            def send_report():\n",
    "                name = entry_name.get().strip()\n",
    "                contact = entry_contact.get().strip()\n",
    "                medical_issues = entry_medical.get().strip()\n",
    "\n",
    "                if not name or not contact or not medical_issues:\n",
    "                    messagebox.showerror(\"Error\", \"Please enter all details.\")\n",
    "                    return\n",
    "\n",
    "                messagebox.showinfo(\"Report Sent\", \"The report has been sent successfully!\")\n",
    "                details_window.destroy()\n",
    "\n",
    "            button_send_report = ttk.Button(details_frame, text=\"Send Report to Therapist\", style=\"CurvedButton.TButton\", command=send_report)\n",
    "            button_send_report.pack()\n",
    "\n",
    "            details_window.mainloop()\n",
    "\n",
    "        button_send_to_therapist = ttk.Button(report_frame, text=\"Send Report\", style=\"CurvedButton.TButton\", command=send_report_to_therapist)\n",
    "        button_send_to_therapist.pack()\n",
    "\n",
    "        report_window.mainloop()\n",
    "\n",
    "    button_end = ttk.Button(button_frame, text=\"End Detection\", style=\"CurvedButton.TButton\", command=stop_detection)\n",
    "    button_end.pack(side='left')\n",
    "\n",
    "    button_report = ttk.Button(button_frame, text=\"Generate Report\", style=\"CurvedButton.TButton\", command=generate_report)\n",
    "    button_report.pack(side='left')\n",
    "\n",
    "    label_img = Label(window2)\n",
    "    label_img.pack()\n",
    "\n",
    "    while not stop_camera:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        face_detector_front = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "        gray_frame_front = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        num_faces = face_detector_front.detectMultiScale(gray_frame_front, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in num_faces:\n",
    "            cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (0, 255, 0), 4)\n",
    "            roi_gray_frame_front = gray_frame_front[y:y + h, x:x + w]\n",
    "            cropped_img_front = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame_front, (48, 48)), -1), 0)\n",
    "\n",
    "            emotion_prediction_front = emotion_model.predict(cropped_img_front)\n",
    "            maxindex_front = int(np.argmax(emotion_prediction_front))\n",
    "            cv2.putText(frame, emotion_dict[maxindex_front], (x+5, y-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            emotion_report.append(maxindex_front)\n",
    "\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "        label_img.configure(image=img_tk)\n",
    "        label_img.image = img_tk\n",
    "\n",
    "        window2.update()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "window = Tk()\n",
    "window.title(\"Emotion Detection\")\n",
    "\n",
    "background_image = Image.open(\"background_image.jpg\")\n",
    "background_image = background_image.resize((1500, 1000), Image.LANCZOS)\n",
    "background_photo = ImageTk.PhotoImage(background_image)\n",
    "\n",
    "label_background = Label(window, image=background_photo)\n",
    "label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "label_background.image = background_photo\n",
    "\n",
    "button_frame = Frame(window, bg='white')\n",
    "button_frame.pack(side='bottom', pady=20)\n",
    "\n",
    "label_heading = Label(window, text=\"Emotion Recognition\", font=(\"Century Gothic\", 30, \"bold\"))\n",
    "label_heading.place(relx=0.5, rely=0.5, anchor='center')\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure(\n",
    "    \"CurvedButton.TButton\",\n",
    "    font=(\"Arial\", 14, \"bold\"),\n",
    "    relief=\"flat\",\n",
    "    background=\"#0f3057\",\n",
    "    foreground=\"black\"\n",
    ")\n",
    "\n",
    "button_start = ttk.Button(button_frame, text=\"Identify Mood\", style=\"CurvedButton.TButton\", command=start_detection)\n",
    "button_start.pack(side='left')\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import Tk, Button, Toplevel, Label, messagebox, Frame, filedialog, Entry\n",
    "from PIL import Image, ImageTk\n",
    "from keras.models import model_from_json\n",
    "from tkinter import ttk\n",
    "\n",
    "# Load JSON and create model\n",
    "json_file = open('model/emotion_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "emotion_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into the model\n",
    "emotion_model.load_weights(\"model/emotion_model.h5\")\n",
    "\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "emotion_report = []  # Variable to store emotion predictions\n",
    "\n",
    "def end_detection():\n",
    "    window2.destroy()\n",
    "    window.deiconify()\n",
    "\n",
    "def start_detection():\n",
    "    global cap, window2, label_img, stop_camera, emotion_report\n",
    "\n",
    "    window.withdraw()  # Hide the first window\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    stop_camera = False\n",
    "    emotion_report = []  # Reset emotion report\n",
    "\n",
    "    window2 = Toplevel()\n",
    "    window2.title(\"Emotion Detection\")\n",
    "\n",
    "    background_image = Image.open(\"background_image.jpg\")\n",
    "    background_image = background_image.resize((1400, 1000), Image.LANCZOS)\n",
    "    background_photo = ImageTk.PhotoImage(background_image)\n",
    "\n",
    "    label_background = Label(window2, image=background_photo)\n",
    "    label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "    label_background.image = background_photo\n",
    "\n",
    "    button_frame = Frame(window2, bg='white', padx=20, pady=20)\n",
    "    button_frame.pack(side='bottom')\n",
    "\n",
    "    def stop_detection():\n",
    "        global stop_camera\n",
    "        stop_camera = True\n",
    "        window2.destroy()\n",
    "        window.deiconify()\n",
    "\n",
    "    def generate_report():\n",
    "        global stop_camera, emotion_report\n",
    "        stop_camera = True\n",
    "\n",
    "        if not emotion_report:\n",
    "            messagebox.showerror(\"Error\", \"No emotions detected. Please try again.\")\n",
    "            return\n",
    "\n",
    "        emotion_count = {}\n",
    "        total_emotions = len(emotion_report)\n",
    "\n",
    "        for emotion in emotion_report:\n",
    "            if emotion in emotion_count:\n",
    "                emotion_count[emotion] += 1\n",
    "            else:\n",
    "                emotion_count[emotion] = 1\n",
    "\n",
    "        emotion_percentage = {}\n",
    "        for emotion, count in emotion_count.items():\n",
    "            percentage = (count / total_emotions) * 100\n",
    "            emotion_percentage[emotion] = percentage\n",
    "\n",
    "        overall_mood = max(emotion_percentage, key=emotion_percentage.get)\n",
    "\n",
    "        report_window = Toplevel()\n",
    "        report_window.title(\"Emotion Report\")\n",
    "\n",
    "        # Set the background image for the report window\n",
    "        background_image = Image.open(\"background_image.jpg\")\n",
    "        background_image = background_image.resize((1500, 1000), Image.LANCZOS)\n",
    "        background_photo = ImageTk.PhotoImage(background_image)\n",
    "        label_background = Label(report_window, image=background_photo)\n",
    "        label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "        label_background.image = background_photo  # Attach the image object to the label to prevent it from being garbage collected\n",
    "\n",
    "        report_frame = Frame(report_window)\n",
    "        report_frame.pack()\n",
    "\n",
    "        for emotion, percentage in emotion_percentage.items():\n",
    "            label = Label(report_frame, text=f\"{emotion_dict[emotion]}: {percentage:.2f}%\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label.pack(anchor='center')\n",
    "\n",
    "        label_overall_mood = Label(report_frame, text=f\"Overall Mood: {emotion_dict[overall_mood]}\", font=(\"Arial\", 20, \"bold\"))\n",
    "        label_overall_mood.pack(anchor='center')\n",
    "\n",
    "        def send_report_to_therapist():\n",
    "            report_window.destroy()\n",
    "            details_window = Toplevel()\n",
    "            details_window.title(\"Patient Details\")\n",
    "\n",
    "            # Set the background image for the details window\n",
    "            background_image = Image.open(\"background_image.jpg\")\n",
    "            background_image = background_image.resize((1500, 1000), Image.LANCZOS)\n",
    "            background_photo = ImageTk.PhotoImage(background_image)\n",
    "            label_background = Label(details_window, image=background_photo)\n",
    "            label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "            label_background.image = background_photo\n",
    "\n",
    "            details_frame = Frame(details_window)\n",
    "            details_frame.pack()\n",
    "\n",
    "            # Add labels and entry fields for patient details\n",
    "            label_name = Label(details_frame, text=\"Name:\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label_name.pack()\n",
    "            entry_name = Entry(details_frame, font=(\"Arial\", 14))\n",
    "            entry_name.pack()\n",
    "\n",
    "            label_contact = Label(details_frame, text=\"Contact No:\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label_contact.pack()\n",
    "            entry_contact = Entry(details_frame, font=(\"Arial\", 14))\n",
    "            entry_contact.pack()\n",
    "\n",
    "            label_medical = Label(details_frame, text=\"Medical Issues:\", font=(\"Arial\", 16, \"bold\"))\n",
    "            label_medical.pack()\n",
    "            entry_medical = Entry(details_frame, font=(\"Arial\", 14))\n",
    "            entry_medical.pack()\n",
    "\n",
    "            def send_report():\n",
    "                name = entry_name.get().strip()\n",
    "                contact = entry_contact.get().strip()\n",
    "                medical_issues = entry_medical.get().strip()\n",
    "\n",
    "                if not name or not contact or not medical_issues:\n",
    "                    messagebox.showerror(\"Error\", \"Please enter all details.\")\n",
    "                    return\n",
    "\n",
    "                messagebox.showinfo(\"Report Sent\", \"The report has been sent successfully!\")\n",
    "                details_window.destroy()\n",
    "\n",
    "            button_send_report = ttk.Button(details_frame, text=\"Send Report to Therapist\", style=\"CurvedButton.TButton\", command=send_report)\n",
    "            button_send_report.pack()\n",
    "\n",
    "            details_window.mainloop()\n",
    "\n",
    "        button_send_to_therapist = ttk.Button(report_frame, text=\"Send Report\", style=\"CurvedButton.TButton\", command=send_report_to_therapist)\n",
    "        button_send_to_therapist.pack()\n",
    "\n",
    "        report_window.mainloop()\n",
    "\n",
    "    button_end = ttk.Button(button_frame, text=\"End Detection\", style=\"CurvedButton.TButton\", command=stop_detection)\n",
    "    button_end.pack(side='left')\n",
    "\n",
    "    button_report = ttk.Button(button_frame, text=\"Generate Report\", style=\"CurvedButton.TButton\", command=generate_report)\n",
    "    button_report.pack(side='left')\n",
    "\n",
    "    label_img = Label(window2)\n",
    "    label_img.pack()\n",
    "\n",
    "    while not stop_camera:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        face_detector_front = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "        gray_frame_front = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        num_faces = face_detector_front.detectMultiScale(gray_frame_front, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in num_faces:\n",
    "            cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (0, 255, 0), 4)\n",
    "            roi_gray_frame_front = gray_frame_front[y:y + h, x:x + w]\n",
    "            cropped_img_front = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame_front, (48, 48)), -1), 0)\n",
    "\n",
    "            emotion_prediction_front = emotion_model.predict(cropped_img_front)\n",
    "            maxindex_front = int(np.argmax(emotion_prediction_front))\n",
    "            cv2.putText(frame, emotion_dict[maxindex_front], (x+5, y-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            emotion_report.append(maxindex_front)\n",
    "\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "        label_img.configure(image=img_tk)\n",
    "        label_img.image = img_tk\n",
    "\n",
    "        window2.update()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "window = Tk()\n",
    "window.title(\"Emotion Detection\")\n",
    "\n",
    "background_image = Image.open(\"background_image.jpg\")\n",
    "background_image = background_image.resize((1500, 1000), Image.LANCZOS)\n",
    "background_photo = ImageTk.PhotoImage(background_image)\n",
    "\n",
    "label_background = Label(window, image=background_photo)\n",
    "label_background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "label_background.image = background_photo\n",
    "\n",
    "button_frame = Frame(window, bg='white')\n",
    "button_frame.pack(side='bottom', pady=20)\n",
    "\n",
    "label_heading = Label(window, text=\"Emotion Recognition\", font=(\"Century Gothic\", 30, \"bold\"))\n",
    "label_heading.place(relx=0.5, rely=0.5, anchor='center')\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure(\n",
    "    \"CurvedButton.TButton\",\n",
    "    font=(\"Arial\", 14, \"bold\"),\n",
    "    relief=\"flat\",\n",
    "    background=\"#0f3057\",\n",
    "    foreground=\"black\"\n",
    ")\n",
    "\n",
    "button_start = ttk.Button(button_frame, text=\"Identify Mood\", style=\"CurvedButton.TButton\", command=start_detection)\n",
    "button_start.pack(side='left')\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emotion_percentage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Prepare data for pie chart\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m emotions \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(emotion_percentage\u001b[39m.\u001b[39mkeys())  \u001b[39m# Extract emotions from the dictionary\u001b[39;00m\n\u001b[0;32m      5\u001b[0m percentages \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(emotion_percentage\u001b[39m.\u001b[39mvalues())  \u001b[39m# Extract percentages from the dictionary\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Plot pie chart\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emotion_percentage' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for pie chart\n",
    "emotions = list(emotion_percentage.keys())  # Extract emotions from the dictionary\n",
    "percentages = list(emotion_percentage.values())  # Extract percentages from the dictionary\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size (width=8, height=6)\n",
    "plt.pie(percentages, labels=emotions, autopct='%1.1f%%')  # Plot the pie chart with percentages and emotion labels\n",
    "plt.title('Emotion Report')  # Set the title of the pie chart\n",
    "\n",
    "# Display the pie chart\n",
    "plt.show()\n",
    "#In this code, we use the previously calculated emotion_percentage dictionary to extract the emotions and percentages. Then, we create a pie chart using plt.pie(), specifying the percentages as the data, labels as the emotions, and using the %1.1f%% format to display percentages with one decimal place. The plt.title() function sets the title of the pie chart to 'Emotion Report'. Finally, plt.show() is used to display the pie chart."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
